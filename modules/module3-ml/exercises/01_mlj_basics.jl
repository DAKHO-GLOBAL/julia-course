# Exercice 1 : Fondamentaux MLJ (Machine Learning en Julia)
# Module 3 : Apprentissage Automatique avec Julia
# Dur√©e : 60 minutes

# üìö AVANT DE COMMENCER
# Lisez le r√©sum√© d'apprentissage : resume_01_mlj_basics.md
# D√©couvrez pourquoi Julia r√©volutionne le Machine Learning !

println("üìö Consultez le r√©sum√© : modules/module3-ml/resume_01_mlj_basics.md")
println("Appuyez sur Entr√©e quand vous √™tes pr√™t √† d√©couvrir le ML Julia...")
readline()

println("ü§ñ Fondamentaux MLJ : Machine Learning avec Julia")
println("="^60)

# Installation et importation des paquets ML
using MLJ
using DataFrames, CSV
using Plots, StatsPlots
using Statistics, Random
using MLJModels

# Configuration pour reproductibilit√©
Random.seed!(42)
MLJ.color_off() # D√©sactiver les couleurs pour la sortie console

# Partie 1 : Chargement et Exploration de Donn√©es
println("üìä Partie 1 : Exploration de Donn√©es avec MLJ")

# Charger un dataset int√©gr√©
println("Chargement du dataset Iris...")
X, y = @load_iris;

println("Informations sur le dataset :")
println("  - Nombre d'observations : ", nrows(X))
println("  - Nombre de features : ", ncols(X))
println("  - Types des colonnes :")
for name in names(X)
    println("    $name : $(eltype(X[!, name]))")
end

println("\nPremi√®res observations :")
println(first(X, 5))

println("\nDistribution des classes :")
countmap_y = Dict()
for classe in y
    countmap_y[classe] = get(countmap_y, classe, 0) + 1
end
for (classe, count) in countmap_y
    println("  $classe : $count observations")
end

# Visualisation des donn√©es
println("\nCr√©ation de visualisations...")
try
    # Scatter plot des features
    p1 = scatter(X.sepal_length, X.sepal_width, 
                group=y, xlabel="Longueur S√©pale", ylabel="Largeur S√©pale",
                title="Iris Dataset - S√©pales")
    
    p2 = scatter(X.petal_length, X.petal_width,
                group=y, xlabel="Longueur P√©tale", ylabel="Largeur P√©tale", 
                title="Iris Dataset - P√©tales")
    
    plot_combined = plot(p1, p2, layout=(1,2), size=(800,300))
    display(plot_combined)
    
    println("‚úÖ Graphiques g√©n√©r√©s avec succ√®s !")
catch e
    println("‚ö†Ô∏è Visualisation non disponible : $e")
end

# Partie 2 : Pr√©paration des Donn√©es
println("\nüîß Partie 2 : Pr√©paration et Nettoyage des Donn√©es")

# Division train/test
println("Division des donn√©es en train/test (70/30)...")
train_indices, test_indices = partition(eachindex(y), 0.7, shuffle=true, rng=42)

X_train = X[train_indices, :]
y_train = y[train_indices]
X_test = X[test_indices, :]
y_test = y[test_indices]

println("Tailles des ensembles :")
println("  - Entra√Ænement : $(length(y_train)) observations")
println("  - Test : $(length(y_test)) observations")

# Standardisation des features
println("\nStandardisation des features...")
standardizer = Standardizer()
mach_standardizer = machine(standardizer, X_train)
fit!(mach_standardizer)

X_train_scaled = MLJ.transform(mach_standardizer, X_train)
X_test_scaled = MLJ.transform(mach_standardizer, X_test)

println("Statistiques apr√®s standardisation (train) :")
for name in names(X_train_scaled)
    col_mean = round(mean(X_train_scaled[!, name]), digits=3)
    col_std = round(std(X_train_scaled[!, name]), digits=3)
    println("  $name : moyenne = $col_mean, √©cart-type = $col_std")
end

# Partie 3 : Mod√®les de Classification
println("\nüéØ Partie 3 : Entra√Ænement de Mod√®les de Classification")

# Mod√®le 1 : Decision Tree
println("Mod√®le 1 : Arbre de D√©cision")
DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree

tree_model = DecisionTreeClassifier(max_depth=5, min_samples_leaf=2)
mach_tree = machine(tree_model, X_train_scaled, y_train)

println("Entra√Ænement de l'arbre de d√©cision...")
fit!(mach_tree)

# Pr√©dictions avec l'arbre
tree_predictions = predict(mach_tree, X_test_scaled)
tree_predictions_mode = mode.(tree_predictions)  # Prendre la classe la plus probable

# √âvaluation
tree_accuracy = accuracy(tree_predictions_mode, y_test)
println("Pr√©cision Arbre de D√©cision : $(round(tree_accuracy, digits=4))")

# Mod√®le 2 : Random Forest
println("\nMod√®le 2 : Random Forest")
RandomForestClassifier = @load RandomForestClassifier pkg=DecisionTree

rf_model = RandomForestClassifier(n_trees=100, max_depth=10)
mach_rf = machine(rf_model, X_train_scaled, y_train)

println("Entra√Ænement du Random Forest...")
fit!(mach_rf)

rf_predictions = predict(mach_rf, X_test_scaled)
rf_predictions_mode = mode.(rf_predictions)

rf_accuracy = accuracy(rf_predictions_mode, y_test)
println("Pr√©cision Random Forest : $(round(rf_accuracy, digits=4))")

# Mod√®le 3 : SVM (si disponible)
println("\nMod√®le 3 : Support Vector Machine")
try
    SVC = @load SVC pkg=LIBSVM
    svm_model = SVC(kernel="rbf", gamma="scale")
    mach_svm = machine(svm_model, X_train_scaled, y_train)
    
    println("Entra√Ænement du SVM...")
    fit!(mach_svm)
    
    svm_predictions = predict(mach_svm, X_test_scaled)
    svm_accuracy = accuracy(svm_predictions, y_test)
    println("Pr√©cision SVM : $(round(svm_accuracy, digits=4))")
    
    svm_available = true
    global svm_predictions_final = svm_predictions
catch e
    println("‚ö†Ô∏è SVM non disponible : $e")
    println("Utilisation des pr√©dictions Random Forest √† la place")
    svm_available = false
    global svm_predictions_final = rf_predictions_mode
end

# Partie 4 : Validation Crois√©e
println("\nüìà Partie 4 : Validation Crois√©e")

println("Validation crois√©e 5-fold pour le Random Forest...")
cv_results = evaluate!(mach_rf, resampling=CV(nfolds=5, shuffle=true, rng=42),
                      measure=accuracy)

println("R√©sultats de la validation crois√©e :")
println("  - Pr√©cision moyenne : $(round(cv_results.measurement[1], digits=4))")

# Calculer intervalle de confiance approximatif
if length(cv_results.per_fold) >= 1 && length(cv_results.per_fold[1]) >= 5
    fold_accuracies = [acc for fold in cv_results.per_fold for acc in fold]
    std_cv = std(fold_accuracies)
    mean_cv = mean(fold_accuracies)
    println("  - √âcart-type : $(round(std_cv, digits=4))")
    println("  - Intervalle confiance 95% : [$(round(mean_cv - 1.96*std_cv, digits=4)), $(round(mean_cv + 1.96*std_cv, digits=4))]")
end

# Partie 5 : M√©triques d'√âvaluation Avanc√©es
println("\nüìä Partie 5 : M√©triques d'√âvaluation D√©taill√©es")

# Matrice de confusion
println("Matrice de confusion (Random Forest) :")
conf_matrix = confusion_matrix(rf_predictions_mode, y_test)

# Affichage de la matrice de confusion
classes = unique(y_test)
println("        Pr√©dictions")
print("R√©alit√©  ")
for c in classes
    print("$c  ")
end
println()

for (i, true_class) in enumerate(classes)
    print("$true_class        ")
    for (j, pred_class) in enumerate(classes)
        # Compter les occurrences
        count = sum((rf_predictions_mode .== pred_class) .& (y_test .== true_class))
        print("$count    ")
    end
    println()
end

# M√©triques par classe
println("\nM√©triques d√©taill√©es par classe :")
for classe in classes
    # Calcul manuel des m√©triques
    true_positives = sum((rf_predictions_mode .== classe) .& (y_test .== classe))
    false_positives = sum((rf_predictions_mode .== classe) .& (y_test .!= classe))
    false_negatives = sum((rf_predictions_mode .!= classe) .& (y_test .== classe))
    
    precision = true_positives / (true_positives + false_positives + 1e-10)
    recall = true_positives / (true_positives + false_negatives + 1e-10)
    f1 = 2 * (precision * recall) / (precision + recall + 1e-10)
    
    println("  Classe $classe :")
    println("    - Pr√©cision : $(round(precision, digits=3))")
    println("    - Rappel : $(round(recall, digits=3))")
    println("    - F1-Score : $(round(f1, digits=3))")
end

# Partie 6 : S√©lection d'Hyperparam√®tres
println("\nüéõÔ∏è Partie 6 : Optimisation d'Hyperparam√®tres")

println("Recherche de grille pour Random Forest...")
# D√©finir la grille de param√®tres
param_grid = (n_trees = [50, 100, 200],
              max_depth = [5, 10, 15])

println("Test de diff√©rentes combinaisons d'hyperparam√®tres :")
best_score = 0.0
best_params = nothing

for n_trees in param_grid.n_trees
    for max_depth in param_grid.max_depth
        # Cr√©er et entra√Æner le mod√®le
        model_test = RandomForestClassifier(n_trees=n_trees, max_depth=max_depth)
        mach_test = machine(model_test, X_train_scaled, y_train)
        fit!(mach_test)
        
        # √âvaluer avec validation crois√©e
        cv_test = evaluate!(mach_test, resampling=CV(nfolds=3, shuffle=true, rng=42),
                           measure=accuracy)
        
        score = cv_test.measurement[1]
        println("  n_trees=$n_trees, max_depth=$max_depth : pr√©cision = $(round(score, digits=4))")
        
        if score > best_score
            best_score = score
            best_params = (n_trees=n_trees, max_depth=max_depth)
        end
    end
end

println("Meilleurs param√®tres : $best_params")
println("Meilleure pr√©cision CV : $(round(best_score, digits=4))")

# Partie 7 : Pipeline ML Complet
println("\nüîÑ Partie 7 : Pipeline ML Int√©gr√©")

println("Cr√©ation d'un pipeline complet...")
# Pipeline avec pr√©processing et mod√®le
pipe = Standardizer() |> RandomForestClassifier(n_trees=best_params.n_trees, 
                                               max_depth=best_params.max_depth)

mach_pipe = machine(pipe, X_train, y_train)
fit!(mach_pipe)

# √âvaluation du pipeline
pipe_predictions = predict(mach_pipe, X_test)
pipe_predictions_mode = mode.(pipe_predictions)
pipe_accuracy = accuracy(pipe_predictions_mode, y_test)

println("Pr√©cision du pipeline complet : $(round(pipe_accuracy, digits=4))")

# Partie 8 : Importance des Features
println("\nüîç Partie 8 : Analyse d'Importance des Features")

# Entra√Æner un mod√®le simple pour analyser l'importance
simple_rf = RandomForestClassifier(n_trees=100)
mach_simple = machine(simple_rf, X_train, y_train)
fit!(mach_simple)

println("Analyse qualitative de l'importance des features :")
println("(Bas√©e sur l'observation des donn√©es)")

# Calcul manuel de corr√©lations simples
feature_names = names(X_train)
println("Corr√©lations approximatives avec les classes :")

for feature in feature_names
    # Calculer une m√©trique simple de s√©paration
    feature_values = X_train[!, feature]
    
    # Calculer la variance inter-classes vs intra-classe
    class_means = Dict()
    for classe in unique(y_train)
        class_indices = y_train .== classe
        class_means[classe] = mean(feature_values[class_indices])
    end
    
    # Mesure de s√©paration simple
    mean_differences = [abs(class_means[c1] - class_means[c2]) 
                       for c1 in keys(class_means) for c2 in keys(class_means) if c1 < c2]
    avg_separation = mean(mean_differences)
    
    println("  $feature : s√©paration inter-classes ‚âà $(round(avg_separation, digits=3))")
end

# Partie 9 : Pr√©dictions sur Nouvelles Donn√©es
println("\nüîÆ Partie 9 : Pr√©dictions sur Nouvelles Observations")

# Cr√©er quelques observations synth√©tiques
nouvelles_obs = DataFrame(
    sepal_length = [5.0, 6.5, 7.0],
    sepal_width = [3.5, 3.0, 3.2],
    petal_length = [1.5, 4.5, 6.0],
    petal_width = [0.2, 1.5, 2.0]
)

println("Nouvelles observations √† classifier :")
println(nouvelles_obs)

# Pr√©dictions avec le pipeline
nouvelles_predictions = predict(mach_pipe, nouvelles_obs)
nouvelles_predictions_mode = mode.(nouvelles_predictions)

println("\nPr√©dictions :")
for (i, pred) in enumerate(nouvelles_predictions_mode)
    proba = maximum(pdf.(nouvelles_predictions[i], [pred]))
    println("  Observation $i : $pred (confiance ‚âà $(round(proba, digits=3)))")
end

# Partie 10 : Comparaison de Mod√®les
println("\nüèÜ Partie 10 : Comparaison Finale des Mod√®les")

models_comparison = DataFrame(
    Mod√®le = ["Arbre de D√©cision", "Random Forest", "Pipeline Optimis√©"],
    Pr√©cision = [tree_accuracy, rf_accuracy, pipe_accuracy],
    Complexit√© = ["Faible", "√âlev√©e", "√âlev√©e"],
    Temps_Entra√Ænement = ["Rapide", "Moyen", "Moyen"]
)

println("Comparaison des mod√®les :")
println(models_comparison)

# Recommandation
best_model_idx = argmax(models_comparison.Pr√©cision)
best_model_name = models_comparison.Mod√®le[best_model_idx]
println("\nüèÖ Mod√®le recommand√© : $best_model_name")
println("Pr√©cision : $(round(models_comparison.Pr√©cision[best_model_idx], digits=4))")

# Partie 11 : Sauvegarde du Mod√®le
println("\nüíæ Partie 11 : Persistance du Mod√®le")

println("Sauvegarde du meilleur mod√®le...")
try
    MLJ.save("./best_iris_model.jlso", mach_pipe)
    println("‚úÖ Mod√®le sauvegard√© dans 'best_iris_model.jlso'")
    
    # Test de rechargement
    loaded_mach = machine("./best_iris_model.jlso")
    test_prediction = predict(loaded_mach, first(X_test, 1))
    println("‚úÖ Test de rechargement r√©ussi")
    
catch e
    println("‚ö†Ô∏è Sauvegarde √©chou√©e : $e")
    println("(Normal dans certains environnements)")
end

# Bilan d'apprentissage
println("\nüìà BILAN D'APPRENTISSAGE")
println("="^60)
println("ü§ñ MA√éTRISE DES FONDAMENTAUX MLJ !")
println("="^60)
println("‚úÖ Comp√©tences Machine Learning d√©velopp√©es :")
println("  - Chargement et exploration de datasets avec MLJ")
println("  - Pr√©paration et standardisation des donn√©es")  
println("  - Entra√Ænement de mod√®les : Decision Tree, Random Forest")
println("  - Validation crois√©e et m√©triques d'√©valuation")
println("  - Optimisation d'hyperparam√®tres par grille")
println("  - Pipelines ML complets avec pr√©processing")
println("  - Analyse d'importance des features")
println("  - Comparaison et s√©lection de mod√®les")
println("  - Persistance et d√©ploiement de mod√®les")

println("\nüéØ COMP√âTENCES TRANSF√âRABLES :")
println("  - M√©thodologie scientifique rigoureuse")
println("  - √âvaluation objective de performance")
println("  - Optimisation syst√©matique d'hyperparam√®tres")
println("  - Workflow reproductible de Machine Learning")

println("\nüöÄ Vous ma√Ætrisez maintenant le cycle complet de ML en Julia !")
println("üìÜ PROCHAINE √âTAPE : 02_dataframes.jl - Manipulation avanc√©e de donn√©es")
println("   (Les pipelines MLJ s'int√®grent parfaitement avec DataFrames)")
println("   (Conseil : Exp√©rimentez avec d'autres datasets !)")